# PaDiM by Swinv2
CNNではなくvision transformerの特徴量を用いてPaDiMを行ったリポジトリです．
以下のモデルに対応しています
* conformer
* transformer base(patch size 16. Imagenet Pretrained)
* masked auto encoder(transformer base. patch size 16.Imagenet Pretrained)
* clip (transformer base. patch size 16. from torchvision)
* swinv2 (patch size 7. Imagenet Pretrained. from torchvision)
### Main usage
Run padim_main.py .
### Environment
* python3.10.10
* pytorch-cuda=11.7
* transformers



# testtsetstset

